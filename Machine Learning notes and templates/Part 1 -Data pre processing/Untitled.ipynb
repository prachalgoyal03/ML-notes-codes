{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 3].values\n",
    "\n",
    "# Taking care of missing data\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "\n",
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "# Encoding the Dependent Variable\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 5.00000000e+01\n",
      "  8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-356e6106d883>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-356e6106d883>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    <h3>Splitting the dataset into the Training set and Test set</h3>\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<h3>Splitting the dataset into the Training set and Test set</h3>\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.70000000e+01\n",
      "  6.70000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.70000000e+01\n",
      "  4.80000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.87777778e+01\n",
      "  5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.80000000e+01\n",
      "  7.90000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.80000000e+01\n",
      "  6.10000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 4.40000000e+01\n",
      "  7.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.50000000e+01\n",
      "  5.80000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04]\n",
      " [0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>above dataset is divided into two 20percent test and 80percent train</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision %.2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.0f'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision %.0f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0e+00 1.0e+00 0.0e+00 3.0e+01 5.4e+04]\n",
      " [0.0e+00 1.0e+00 0.0e+00 5.0e+01 8.3e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>we need to put variables on same scale</h5>\n",
    "<h5>or else ml model will dominate one value and ignore other</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc_X.fit_transform (X_train)\n",
    "X_test = sc_X.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>in test set we didnt use fit because we already did it in train set</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          2.64575131 -0.77459667  0.26306757  0.12381479]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.25350148  0.46175632]\n",
      " [-1.         -0.37796447  1.29099445 -1.97539832 -1.53093341]\n",
      " [-1.         -0.37796447  1.29099445  0.05261351 -1.11141978]\n",
      " [ 1.         -0.37796447 -0.77459667  1.64058505  1.7202972 ]\n",
      " [-1.         -0.37796447  1.29099445 -0.0813118  -0.16751412]\n",
      " [ 1.         -0.37796447 -0.77459667  0.95182631  0.98614835]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.59788085 -0.48214934]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
